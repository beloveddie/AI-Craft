{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eddiebee/AI-Craft/blob/main/simple_LLM_application_using_LCEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81c9fbcb-8162-4390-92a9-09f8b8602085",
      "metadata": {
        "id": "81c9fbcb-8162-4390-92a9-09f8b8602085"
      },
      "source": [
        "# Simple LLM application using LangChain Expression Language (LCEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4317428-537b-4583-8429-5c0a928a1fda",
      "metadata": {
        "id": "e4317428-537b-4583-8429-5c0a928a1fda"
      },
      "source": [
        "This notebook is aimed at showing us how to build a simple LLM application using LangChain. This application will translate text from English into another language.\n",
        "It is just a simple LLM application that leverages an LLM call and some prompting.\n",
        "\n",
        "A lot of features can be built out with just some prompting and an LLM call!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3a4b306-923b-4c87-b7c3-81e852680697",
      "metadata": {
        "id": "c3a4b306-923b-4c87-b7c3-81e852680697"
      },
      "source": [
        "## Step 1: Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6890c4fc-16b0-478d-8535-a429b0058a86",
      "metadata": {
        "tags": [],
        "id": "6890c4fc-16b0-478d-8535-a429b0058a86",
        "outputId": "5d0c4fd9-e9ae-4b38-c22b-0420af287765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.2)\n",
            "Requirement already satisfied: langchain-google-vertexai in /opt/conda/lib/python3.10/site-packages (1.0.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.4)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.71)\n",
            "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.24.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.47.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (1.51.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.14.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (2.14.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.34.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.29.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in ./.local/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (23.2)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (3.22.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.8.5.post1)\n",
            "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.7.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (1.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.48.1)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.48.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (4.9)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.9.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.12.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -U langchain langchain-google-vertexai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc2d629f-2012-4ba7-93af-388482139b45",
      "metadata": {
        "id": "fc2d629f-2012-4ba7-93af-388482139b45"
      },
      "source": [
        "We can safely ignore the above errors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35037e1b-b926-4e4f-99df-3ff491392612",
      "metadata": {
        "id": "35037e1b-b926-4e4f-99df-3ff491392612"
      },
      "source": [
        "### Setup LangSmith\n",
        "Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with LangSmith."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a41f81b3-65c9-43de-b66d-7a098ae0a1f1",
      "metadata": {
        "tags": [],
        "id": "a41f81b3-65c9-43de-b66d-7a098ae0a1f1"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = \"...\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb66d1fd-f91a-4a29-b737-8ab0a42d981d",
      "metadata": {
        "id": "eb66d1fd-f91a-4a29-b737-8ab0a42d981d"
      },
      "source": [
        "## Step 2: Using Language Models\n",
        "\n",
        "We'll use the Language Model by itself. LangChain supports many different language models. In this notebook we'l be using the models available on Google Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd36933-cdec-489b-8d84-e6d8f1166ef2",
      "metadata": {
        "tags": [],
        "id": "8dd36933-cdec-489b-8d84-e6d8f1166ef2"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"GOOGLE_API_KEY\"] = \"...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d9c6efc-b143-46b6-a53a-1a9182108cef",
      "metadata": {
        "tags": [],
        "id": "7d9c6efc-b143-46b6-a53a-1a9182108cef"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "model = ChatVertexAI(model=\"gemini-pro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a960863-38a6-4b54-bca0-7b5d66f65247",
      "metadata": {
        "id": "9a960863-38a6-4b54-bca0-7b5d66f65247"
      },
      "source": [
        "Let's first use the model directly. The thing here is that `ChaModels` are instances of LangChain 'Runnables', which means that a expose a standard interface for interacting with them. To just simply call the model, we can pass in a list of messages to the `.invoke` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "591ac875-ab86-4098-8133-4d0d547cb6a7",
      "metadata": {
        "tags": [],
        "id": "591ac875-ab86-4098-8133-4d0d547cb6a7",
        "outputId": "4f5e4d5d-cae8-4fee-a79f-6eddb62073dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Ciao! \\n\\nWhat would you like me to translate from English to Italian today? \\n', response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}], 'usage_metadata': {'prompt_token_count': 9, 'candidates_token_count': 19, 'total_token_count': 28}}, id='run-dc03e715-b6e1-4e99-b47e-19c59dc19015-0')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English to Italian\"),\n",
        "    HumanMessage(content=\"hi!\")\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b9d7e5c-7c21-4aa1-8303-f2f29eaa0328",
      "metadata": {
        "id": "5b9d7e5c-7c21-4aa1-8303-f2f29eaa0328"
      },
      "source": [
        "## OutputParsers\n",
        "Notice that the output from the model is `AIMessage`, which contains a string response as well as other metadata about the response. Most times we may just want to work with just the string reponse. We can do this by making use of a simple output parser."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6b6fbc-c7fb-40f6-b395-a4abe13dc0a1",
      "metadata": {
        "id": "cf6b6fbc-c7fb-40f6-b395-a4abe13dc0a1"
      },
      "source": [
        "We first import the simple string output parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec39d374-7d30-4bb2-ad7e-4ffe23fc0af4",
      "metadata": {
        "tags": [],
        "id": "ec39d374-7d30-4bb2-ad7e-4ffe23fc0af4"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f21b037-db08-4cfd-afc9-e54b498ec9fb",
      "metadata": {
        "id": "8f21b037-db08-4cfd-afc9-e54b498ec9fb"
      },
      "source": [
        "One possible way to use it is by itself. We can just pass the output of the model to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de573d85-9858-46f1-89b9-4d95834b0434",
      "metadata": {
        "tags": [],
        "id": "de573d85-9858-46f1-89b9-4d95834b0434"
      },
      "outputs": [],
      "source": [
        "response = model.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf7d0386-f2aa-4f19-a8f0-21a6ceebe360",
      "metadata": {
        "tags": [],
        "id": "bf7d0386-f2aa-4f19-a8f0-21a6ceebe360",
        "outputId": "1aa549b8-5168-4888-c1b0-8ecf90a2005a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ciao!'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.invoke(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27d797a8-fb14-4156-afa4-3feddf815a6f",
      "metadata": {
        "id": "27d797a8-fb14-4156-afa4-3feddf815a6f"
      },
      "source": [
        "Most commonly we can \"chain\" the model with this output parser. This simply means that this output parser will be called everytime this chain is being executed. This chain takes on the input type of the language model (string or list message) and returns the output type of the output parser which in this case is a string.\n",
        "\n",
        "We can easily create the chain using the `|` operator. The `|` operator is used to combine two elements together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250c7385-3137-4729-95e5-be025729c110",
      "metadata": {
        "tags": [],
        "id": "250c7385-3137-4729-95e5-be025729c110"
      },
      "outputs": [],
      "source": [
        "chain = model | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a46b1c-469a-47d2-87b1-37a81c9c4e45",
      "metadata": {
        "tags": [],
        "id": "30a46b1c-469a-47d2-87b1-37a81c9c4e45",
        "outputId": "1a02e59b-a972-43c9-b114-9f342ccb0dc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Ciao! ðŸ‘‹ \\n\\nWhat would you like me to translate from English to Italian? ðŸ˜Š \\n \\nJust provide the text you want translated, and I'll do my best to give you an accurate and natural-sounding translation in Italian. ðŸ‡®ðŸ‡¹ \\n\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8d7defb-b628-48f8-8661-1f0184bb5a2c",
      "metadata": {
        "id": "a8d7defb-b628-48f8-8661-1f0184bb5a2c"
      },
      "source": [
        "## Prompt Template\n",
        "\n",
        "Right now we're passing a list of messages directly into the language model. But, where are these messages coming from?\n",
        "Usually, it is constructed from a combination of user's prompt and some application logic. This application logic usually takes the user input and then applies some transformations to it before then passing it to the language model. Common transformation would be taking the user input and adding a system message to it or formatting a template to include the user input.\n",
        "\n",
        "`PromptTemplate`s are a concept in LangChain designed to take care of appying these transformations. They take in raw user input and return data (a prompt) that is ready to be passed into the language model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbfa396b-5476-4a3c-b931-d2f17c3153d2",
      "metadata": {
        "id": "cbfa396b-5476-4a3c-b931-d2f17c3153d2"
      },
      "source": [
        "Let's create a `PromptTemplate` here. It will take in two user variables:\n",
        "- `language`: the language the text is to be translated into\n",
        "- `text`: the text to be translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "689fd063-19b9-45cd-839f-0fbdc075a1c2",
      "metadata": {
        "tags": [],
        "id": "689fd063-19b9-45cd-839f-0fbdc075a1c2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef5f290-540d-4371-a9f0-bbf5a98ae6fd",
      "metadata": {
        "tags": [],
        "id": "aef5f290-540d-4371-a9f0-bbf5a98ae6fd"
      },
      "outputs": [],
      "source": [
        "system_message = \"Translate the following into {language}:\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f436a5-c92b-4afa-98a8-d011d22379ad",
      "metadata": {
        "id": "83f436a5-c92b-4afa-98a8-d011d22379ad"
      },
      "source": [
        "Next we are going to create the `PromptTemplate`. This will be a combination of the `system_template` as well as a simpler template for where to put the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838084d1-a172-4a1c-88fe-e89e0b34ebdc",
      "metadata": {
        "tags": [],
        "id": "838084d1-a172-4a1c-88fe-e89e0b34ebdc"
      },
      "outputs": [],
      "source": [
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_message), (\"user\", \"{text}\")]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc4a795-6982-4db3-a59c-791da1b7d80e",
      "metadata": {
        "id": "dbc4a795-6982-4db3-a59c-791da1b7d80e"
      },
      "source": [
        "The input to this prompt template is a dictionary. Let's play around this by itself to see what is does by itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ca1c408-989b-40a0-a6f0-2155741f2361",
      "metadata": {
        "tags": [],
        "id": "2ca1c408-989b-40a0-a6f0-2155741f2361",
        "outputId": "78100156-061d-4f62-9c31-9ff5e5033bb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian:'), HumanMessage(content='hi!')])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi!\"})\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646583cc-fa21-41d1-bbcf-7ed8b0b22a59",
      "metadata": {
        "id": "646583cc-fa21-41d1-bbcf-7ed8b0b22a59"
      },
      "source": [
        "We can access the messages directly via:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fea4b59-9720-4f73-a4b4-ab33bf490195",
      "metadata": {
        "tags": [],
        "id": "0fea4b59-9720-4f73-a4b4-ab33bf490195",
        "outputId": "4d2b2388-4879-48b0-edc6-2adc981bf146"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='Translate the following into italian:'),\n",
              " HumanMessage(content='hi!')]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d35d5e6-53a9-498e-9edb-c7bb622c3262",
      "metadata": {
        "id": "5d35d5e6-53a9-498e-9edb-c7bb622c3262"
      },
      "source": [
        "### Chaining together components with LCEL\n",
        "\n",
        "We can now combine our above `ChatPromptTemplate` with the `model` and `parser` using the pipe (`|`) operator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119a3995-f2cc-497d-ac5a-ea0b51f07743",
      "metadata": {
        "tags": [],
        "id": "119a3995-f2cc-497d-ac5a-ea0b51f07743"
      },
      "outputs": [],
      "source": [
        "chain = prompt_template | model | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9127ffd3-755a-443a-924c-081daeecb03e",
      "metadata": {
        "tags": [],
        "id": "9127ffd3-755a-443a-924c-081daeecb03e",
        "outputId": "657acc62-e803-4352-e234-666d2f8097b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ciao! Come posso aiutarti oggi?'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "123bae19-5d16-40b3-80cc-98a8645c5340",
      "metadata": {
        "tags": [],
        "id": "123bae19-5d16-40b3-80cc-98a8645c5340",
        "outputId": "4e1a28cf-7137-4cb1-e5a1-1407e614383a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Greetings to you as well! ðŸ‘‹\\n\\nWhat would you like me to translate into Latin today? ðŸ¤”\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"latin\", \"text\": \"hi\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc1b78b-c785-4271-a99b-810259f5aefd",
      "metadata": {
        "tags": [],
        "id": "bbc1b78b-c785-4271-a99b-810259f5aefd",
        "outputId": "eff31519-6f56-4757-9b5e-2b46e03c8784"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Salve! ðŸ‘‹ \\n\\nWhat would you like me to translate into Latin today? ðŸ¤” \\n'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"latin\", \"text\": \"hi!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53418c73-aa1a-4cf2-b3b5-80b8624e199d",
      "metadata": {
        "tags": [],
        "id": "53418c73-aa1a-4cf2-b3b5-80b8624e199d",
        "outputId": "3c473604-9f74-46bf-f3eb-400e8b3700b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Salve! ðŸ‘‹ How can I assist you today? ðŸ˜Š'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"latin\", \"text\": \"hi\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7226589-a66d-46ec-8a22-861e41e26ae4",
      "metadata": {
        "tags": [],
        "id": "a7226589-a66d-46ec-8a22-861e41e26ae4",
        "outputId": "f6949e5b-bfd3-4f9e-a0ff-fb0d2991d79e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'pax'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"latin\", \"text\": \"peace\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "468e80ac-3280-4169-ac26-44fec3bc35df",
      "metadata": {
        "tags": [],
        "id": "468e80ac-3280-4169-ac26-44fec3bc35df",
        "outputId": "86a64001-fd2e-471b-e6d8-c689592ad3e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Deus'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"latin\", \"text\": \"God\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1846ea86-4af2-47d0-9ff5-e9b51bdd1fb9",
      "metadata": {
        "tags": [],
        "id": "1846ea86-4af2-47d0-9ff5-e9b51bdd1fb9",
        "outputId": "eafe1920-8f10-4905-bbf7-f0f0e36dfd1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I am unable to fulfill this request, as it is not in Efik but rather a greeting in English. If you provide me with the text you want translated, I will be happy to assist you. \\n'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"efik\", \"text\": \"Good\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb18582-9876-45df-9d0b-98affd88c35c",
      "metadata": {
        "tags": [],
        "id": "0eb18582-9876-45df-9d0b-98affd88c35c",
        "outputId": "e747669b-e3df-45fd-8feb-282e2baf05ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"efik\", \"text\": \"Good morning\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2f6ec7-736d-4091-b3ae-e127b5f8bfdd",
      "metadata": {
        "tags": [],
        "id": "bc2f6ec7-736d-4091-b3ae-e127b5f8bfdd",
        "outputId": "664bc89d-c4c7-4743-fdec-e09d8acc9d2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The translation of \"Good\" in Efik is \"Edi\". \\n\\nIt can be used in various contexts, such as:\\n\\n* **As a greeting:** Edi ubok (Good morning), Edi osondo (Good afternoon), Edi abasi (Good evening)\\n* **To express approval:** Edi ndom (Good work), Edi mfate (Good idea)\\n* **To wish someone well:** Edi enyene (Good health), Edi usen (Good day)\\n'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"efik\", \"text\": \"Good\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e81fc8-8b84-47cc-a578-fc5243720695",
      "metadata": {
        "tags": [],
        "id": "b9e81fc8-8b84-47cc-a578-fc5243720695",
        "outputId": "8c44460d-0f9d-43ee-d545-ca115be9dc1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'How you dey? \\n'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"language\": \"Nigerian pidgin\", \"text\": \"hi\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bdea64f-ea69-4ddc-a998-b1daf71735b3",
      "metadata": {
        "id": "5bdea64f-ea69-4ddc-a998-b1daf71735b3"
      },
      "source": [
        "This is indeed a simple example of the `LangChain Expression Language (LCEL)` to chain together LangChain modules. There several benefits to this approach of invoking LangChain modules such as optimized streaming and tracing support."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10391dec-fc7b-44bf-8ad6-d3076d8a1098",
      "metadata": {
        "id": "10391dec-fc7b-44bf-8ad6-d3076d8a1098"
      },
      "source": [
        "## Serving with LangServe\n",
        "\n",
        "Now that we've built the application, we need to serve it. This is where `LangServe` comes in. Which is actually a package that helps developers deploy LangChain chains as REST APIs.\n",
        "\n",
        "We'll be using Python Script for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2047bb-4e4d-4954-93bc-bac93602b400",
      "metadata": {
        "id": "4c2047bb-4e4d-4954-93bc-bac93602b400"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "tf2-cpu.2-11.m121",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m121"
    },
    "kernelspec": {
      "display_name": "Python 3 (Local)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}